{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理论笔记\n",
    "\n",
    "\n",
    "## 监督学习与无监督学习的区别\n",
    "\n",
    "区别是：训练数据是否有标记，有为监督，否则无监。\n",
    "\n",
    "- 监督学习（Supervised Learning）\n",
    "  - 回归regression（连续值变化）【例如，根据已有房价建模，预测房价】\n",
    "  - 分类classification（离散值分类）【例如，根据已有肿瘤形态特征信息与肿瘤是否恶性建模，预测一个给定形态的肿瘤是否恶性】\n",
    "- 无监督学习（Unsupervised Learning）：\n",
    "  - 聚类cluster【例如，鸡尾酒会算法，分离背景音和主要声源音；例如，根据互动而猜测社交网络】\n",
    "\n",
    "## 代价函数（Cost Function）\n",
    "\n",
    "机器学习的目标是通过训练数据不断优化假设函数 $h$，使得相应的代价函数 $J$ 最小。\n",
    "\n",
    "在线性回归(Linear Regression)问题中，我们的假设函数定义为 $h_\\theta(x) $，相应的代价函数定义为 $ J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m (h^{(i)} (x)- y^{(i)})^2 $，目标是找到使得相应的代价函数 $J(\\theta)$ 最小的 $\\theta$。\n",
    "\n",
    "在逻辑回归（Logistic Regression）问题中，若将假设函数 $h_\\theta(x)$ 代入用于线性回归的代价函数形式，得到的函数 $J(\\theta)$ 对于 $\\theta$ 是一个非凸函数（non-convex function），\n",
    "\n",
    "> 所谓凸函数（convex function），目前而言可以二次函数为例\n",
    "\n",
    "从而有许多极值点，在此情况下用梯度下降法得到的解不一定是全局最优解。因此在逻辑回归问题中，代价函数可改变为 $ J(\\theta) = -y(log(h_\\theta(x)))-(1-y)(log(1-h_\\theta(x))) $。这实际上是通过统计学上的**极大似然估计**计算得到的表达式。\n",
    "\n",
    "> - **思考 1：代价函数的定义式，类似于统计学上方差定义式，两者之间是否有什么关系？**\n",
    "> > 例如：方差（Variance）表示样本点偏离样本均值的程度，方差越小，表示该样本点越接近样本均值；而代价（Cost）越小，表示我们的假设越接近真实函数（至少在已有数据覆盖到的范围内）\n",
    "\n",
    "> - **思考 2：考虑到统计与机器学习的关系，还有多少机器学习的概念与统计学概念在定义类似/相关度大？**\n",
    "\n",
    "> - **思考 3：这些形式上的相似，是否意味着内涵上的相似？导致处理方法上的相似？**\n",
    "\n",
    "> - **思考 4：可能涉及的知识点包括 极大似然估计，凸优化**\n",
    "\n",
    "- 代价函数有很多种，这是其中一种\n",
    "- 假设函数 h 是自变量（通常记为 x 或 $x^{(1)}, x^{(2)}, \\cdots$）的函数，而代价函数 J 是 h 中独立于自变量的参数的函数\n",
    "\n",
    "## 梯度下降法（Gradient Descent）\n",
    "\n",
    "> 该方法既适用于线性回归（Linear Regression）问题，又适用于逻辑回归（Logistic Regression）问题。\n",
    "> \n",
    "> 算法形式甚至一致，但由于**假设不同**（想看看 $h_\\theta(x)$ 的定义式），实际上是不同的算法。\n",
    "\n",
    "以单变量线性回归问题为例：\n",
    "\n",
    "假设代价函数 $J$ 是 $ \\theta_0 $ 与 $ \\theta_1 $ 的函数\n",
    "\n",
    "概述：\n",
    "1. 为 $ \\theta_0 $ 与 $ \\theta_1 $ 设置初值\n",
    "2. 反复更新 $ \\theta_0 $ 与 $ \\theta_1 $（每一次都**同时更新两个变量**），直到 $J(\\theta_0, \\theta_1)$ 最小\n",
    "    - $temp0 := \\theta_0 - \\alpha * \\frac{\\partial J}{\\partial \\theta_0}$\n",
    "    - $temp1 := \\theta_1 - \\alpha * \\frac{\\partial J}{\\partial \\theta_1}$\n",
    "    - $ \\theta_0 := temp0 $;\n",
    "    - $\\theta_1 := temp1 $;\n",
    "    - 这里的 $\\alpha$ 被称为「学习速率」，它决定了每次更新 $\\theta_j$ 的大小 \n",
    "\n",
    "\\***补充**：这个偏导数 $\\frac{\\partial J}{\\partial \\theta_j} = \\theta_j - \\alpha \\sum_{i = 1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$ 对线性回归问题和逻辑回归问题的表达式均成立\n",
    "\n",
    "在多变量线性回归问题中：\n",
    "\n",
    "例如有如下 3 项特征（$n = 3$），训练样本数为 4（$m = 4$）\n",
    "\n",
    "房屋面积 | 房间数 | 使用年限 | 价格\n",
    "-------------|-----------|-------------|---------\n",
    "80 | 4 | 2 | 5000\n",
    "90 | 5 | 3 | 9000\n",
    "30   | 2 | 10 | 1000\n",
    "10 | 1 | 20 | 800\n",
    "\n",
    "其中，每种特征记为下标 $j$，样本序号记为上标 $(i)$，从而第 3 个样本为 $x^{(3)}$，该样本的第 2 个特征（这里是房间数）为 $x^{(3)}_2$\n",
    "\n",
    "此时的假设函数形式为 $h_\\theta(x) = \\theta_0 + \\theta_1 * x_1 + \\theta_2 * x_2 + \\theta_3 * x_3$\n",
    "\n",
    "为了方便起见，假设还有 1 个特征 $x_0$（$\\forall i, x^{(i)}_0 = 1$），那么参数 $\\theta$ 与自变量 $x$ 均可写成矩阵（列矩阵/向量）形式，即 $h_\\theta(x) = \\theta^{T}x$；如此改写后，代价函数也可以相应改写，同时把 $J$ 视为 $\\theta$ 的函数，而不是 $\\theta_1\\cdots\\theta_n$ 的函数\n",
    "\n",
    "### 【技巧】梯度下降法使用技巧之：特征缩放（Feature Scaling）\n",
    "\n",
    "为了让梯度下降法进行得更快，首先对特征值进行正规化（Normalization），即将所有特征值处以该特征的范围（最大值与最小值之差），以便使得所有特征值取值范围都在 -1 与 +1 之间；通常进行的是均值正规化（Mean Normalization），即（？形式类似或者内涵类似？。。。）统计中的标准化，不过分母的标准差 s 实际只要放入该特征的范围（最大值与最小值之差）即可，这样处理之后，所有特征值取值范围均在 -0.5 与 +0.5 之间（一般在这个范围内，即便不在，也偏离得不远）。\n",
    "\n",
    "### 【技巧】梯度下降法使用技巧之：学习速率（Learning Rate）\n",
    "\n",
    "如果梯度下降法运行正常，结果将收敛，表现为代价函数 $J(\\theta)$ 随 $\\theta$ 下降；当下降到某个时候 $J(\\theta)$ 基本持平不再改变时，结果收敛，这里的 $\\theta$ 就是我们想要的。\n",
    "\n",
    "如果梯度下降法运行结果是代价函数 $J(\\theta)$ 随 $\\theta$ 增大而增大，这表明结果发散。通常这是由于**学习速率 $\\alpha$ 过大**导致的；需要把学习速率减小（但也不能过小，否则可能收敛过慢）。\n",
    "\n",
    "## 【技巧】拟合成功的 2 个技巧：特征选择与多项式回归\n",
    "\n",
    "拟合成功的技巧之一是：根据不同情况（即实际影响输出的因素）选择不同的特征。例如同样对于房价而言，到底需要 2 个参数（例如房子沿街宽度 w、房子纵深 d），还是需要 1 个参数（例如房间面积 area = w \\* d）？恰当选择特征是拟合成功的关键之一。\n",
    "\n",
    "拟合成功的技巧之二是：在需要用非线性方程来拟合数据时，令非线性的幂为下标不同的一次项。例如当判断出数据可能拟合 3 次方程时，例如 $h_\\theta(x) = \\theta_0 + \\theta_1 * x + \\theta_2 * x^{2} + \\theta_3 * x^{3} $ 时，可令 $x_1 = x, x_2 = x^{2}, x_3 = x^{3}$。这样，待拟合函数则成为了线性形式，便可以用已知方法拟合出高次方程的未知参数（待定系数）了。\n",
    "\n",
    "## 正规方程（Normalization Equation）\n",
    "\n",
    "假设每个训练样本均有 $n$ 个特征，则第 i 个样本可由一个向量表示为：$\\begin{bmatrix}x^{(i)}_1\\\\x^{(i)}_2\\\\\\vdots\\\\x^{(i)}_n\\end{bmatrix}$\n",
    "\n",
    "构造矩阵 $X = \n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_1&x^{(1)}_2&\\cdots&x^{(1)}_n\\\\\n",
    "x^{(2)}_1&x^{(2)}_2&\\cdots&x^{(2)}_n\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "x^{(m)}_1&x^{(m)}_2&\\cdots&x^{(m)}_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "则所求参数 $\\theta = (X^{T}X)^{-1}X^{T}y$\n",
    "\n",
    "### 如果 $X^{T}X$ 不可逆怎么办\n",
    "\n",
    "检查 2 项：\n",
    "\n",
    "1. 是否存在线性相关的特征？若是，减少特征\n",
    "2. 特征数(列数)是否比样本数（行数）多？若是，除了考虑减少特征，之后可能介绍的新算法（？。。。）外\n",
    "\n",
    "### 与梯度下降法的对比\n",
    "\n",
    "梯度下降法（Gradient Descent） | 正规方程法（Normal equation）\n",
    "---------------------------|---------------------------\n",
    "需要自行确定学习速率$\\alpha$|**不需要**确定学习速率，但需要计算 $(X^{T}X)^{-1}$\n",
    "需要迭代多次以求出最优解（\\*）|一次计算即可得到最优解\n",
    "在训练样本数较大时计算仍较快|时间复杂度为$O(n^{3})$，当 $n>10^{4}$时基本不考虑\n",
    "\n",
    "\\*注：使代价函数 $J(\\theta)$ 最小的 $\\theta$\n",
    "\n",
    "## 逻辑回归（Logistic Regression）\n",
    "\n",
    "### 线性回归（Linear Regression）？并不总是好用\n",
    "\n",
    "这实际上是一个分类（Classification）算法，用于标签（y）值为离散的情况。\n",
    "\n",
    "线性回归似乎能用于分类问题，例如：\n",
    "\n",
    "$$\n",
    "y =\n",
    "\\begin{cases}\n",
    "0, && x = 1, 2, 3 \\\\\n",
    "1, && x = 4, 5, 6\n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "在这种情况下，很容易能拟合出一条直线，例如可能是 $h_\\theta(x) = \\frac{1}{6}x$，然后我们可以约定，使 $h_\\theta(x) \\le 0.5$ 的那些 $x$ 都属于 0 类，剩下的属于 1 类。\n",
    "\n",
    "但线性回归并不总是有效。有一种情况会让我们明白：例如当上述例子增加一个点 (20, 1) 时，拟合出的直线是 $h_\\theta = \\frac{1}{20}x$，但此时使 $h_\\theta(x) \\le 0.5$ 的那些 $x$ 中将有许多点不属于 0 类。\n",
    "\n",
    "那么你也许会注意到我上面使用了「约定」一词，你是不是会问：「那我们改变约定不就可以了吗？」问题是我们希望找到一种尽可能在一类问题中通用的约定。所以在这种情况下，线性回归用来解决分类问题就见得捉襟见肘了\n",
    "\n",
    "### 逻辑回归：使用 S 型函数（Sigmoid function）\n",
    "\n",
    "我们可以使用 [S 型函数（Sigmoid function）](https://en.wikipedia.org/wiki/Sigmoid_function) 作为假设函数来帮助我们分类。该模型为$g(z) = \\frac{1}{1 + e^{-z}}$，其中$z = \\theta^{T}x$，故 $g(z) = g(\\theta^{T}x) = h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^{T}x}}$\n",
    "\n",
    "> 该函数是[逻辑函数（Logistic function）](https://en.wikipedia.org/wiki/Logistic_function)的一个特例，这就是「逻辑回归」（Logistic Regression）名字的由来\n",
    "\n",
    "### 决策边界（Decision Boundary）\n",
    "\n",
    "**决策边界**就是分类边界。\n",
    "\n",
    "函数 $h_\\theta(x) = g(\\theta^{T}x) = P(y = 1|x;\\theta)$ 的意义即\n",
    "\n",
    "> 给定 $x$ 且参数为 $\\theta$ 的条件下，$y = 1$ 的概率\n",
    "\n",
    "假定 $h_\\theta(x) \\ge 0.5 \\Rightarrow y = 1; h_\\theta(x) < 0.5 \\Rightarrow y = 0$，\n",
    "\n",
    "其中\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "& &z \\ge 0 &\\Rightarrow& g(z) \\ge 0.5 \\\\\n",
    "& \\Leftrightarrow & z = \\theta^{T}x \\ge 0 &\\Rightarrow& g(\\theta^{T}x) = h_\\theta(x) \\ge 0.5 \\\\\n",
    "& \\Leftrightarrow & \\theta^{T}x \\ge 0 &\\Rightarrow& h_\\theta(x) \\ge 0.5 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "也就是说，区域如何划分（即边界如何选取，即如何分类——我们的目标就是要找到一个合适的分类函数，由得到的点输入，输出该点对应的分类），只与参数 $\\theta$ 有关（与训练数据无关）。一旦 $\\theta$ 定下，则 $h_\\theta(x)$ 的表达式也就跟着定下，决策边界就是 $h_\\theta(x) = 0$ 对应的曲线。\n",
    "\n",
    "### 正则化（Regularization）\n",
    "\n",
    "拟合函数时，有 2 种问题可能出现：\n",
    "\n",
    "1. 欠拟合（Underfit, high bias）：例如用一次函数来拟合明显是符合二次函数分布趋势的点，训练数据集里有许多点无法被假设函数拟合\n",
    "2. 过拟合（Overfit, high variance）：精确通过训练数据集中的每一个点，但这将使假设函数对数据集以外的点预测能力降低\n",
    "\n",
    "其中，解决过拟合问题有 2 种方法：\n",
    "\n",
    "1. 减少特征（人工选择特征；利用算法自动选择）\n",
    "2. **正则化**（向代价函数 $J(\\theta)$ 中添加一些正则化项，通过对正则化项的「惩罚代价」提高，从而减少参数量级/数值，使某些参数几乎为 0，不起作用）\n",
    "\n",
    "但是应该添加哪些项目为正则化项呢？我们通常添加的是 $\\lambda\\sum_{j = 1}^m\\theta_j^{2}$，\n",
    "\n",
    "> **注意 1：正则化项目不包含 $\\theta_0$！**\n",
    "> **注意 2：$\\lambda$ 若过大，反倒可能使假设函数变为欠拟合状态**\n",
    "\n",
    "即让除了 $\\theta_0$ 以外的所有参数都参与正则化过程。\n",
    "\n",
    "> 这就意味着，使用梯度下降法（Gradient Descent）更新 $\\theta_j$ 时，$\\theta_0$ 应独立更新（其余 $\\theta_j$ 包含了正则化项目，则同时更新）\n",
    "\n",
    "正则化方法还有一个好：\n",
    "\n",
    "> 保证正规方程法（Normal Equation）中求逆矩阵的项一定是可逆（非奇异）的。\n",
    "\n",
    "在正规方程法中使用正则化方法时，\n",
    "\n",
    "$$\n",
    "\\theta = (X^{T}X + \\lambda A)^{-1}X^{T}y,\n",
    "$$\n",
    "\n",
    "其中，\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "0&0&0&\\cdots&0\\\\\n",
    "0&1&0&\\cdots&0\\\\\n",
    "0&0&1&\\cdots&0\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "0&0&0&\\cdots&1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## 神经网络（Neural Network）\n",
    "\n",
    "### 为什么要用神经网络？（Why NN?）\n",
    "\n",
    "在以下 2 种情况下，使用逻辑回归等方法拟合计算量太大/不准确\n",
    "\n",
    "1. 当需要拟合的多项式太复杂时：计算量大，或不准确（例如可能出现过拟合的情况）\n",
    "2. 特征数较多时，例如训练对象是位图：计算量太大\n",
    "\n",
    "而神经网络（NN）在执行复杂的分类任务时非常有效。当然，由于其计算量较大，伴随着近年来计算技术的突破（包括硬件的支持），NN 重新开始又受到了关注。。。\n",
    "\n",
    "### （人工）神经网络的基本单位：（人工）神经元（Neuron）\n",
    "\n",
    "人工神经元是一个（一对一的）逻辑分类器，由 2 层构成：\n",
    "\n",
    "1. 输入层\n",
    "2. 输出层\n",
    "\n",
    "一种简单的示意图是：\n",
    "\n",
    "- 输入层为若干个结点 $x_i$，输出层有 1 个结点 $h_\\theta(x)$\n",
    "- 输入层的所有结点（有时可能会加上 1 个偏置单元 bias unit，即常数项）通过有向边指向输出层的那 1 个结点，边权值即为参数（在神经网络中又被称为「权重」（weight）？。。。）\n",
    "\n",
    "目前我们使用的神经元是带 S 型激励函数（Sigmoid function）的神经元。\n",
    "\n",
    "### 神经元如何组成神经网络：隐藏层（Hidden Layer）与激励（Activation）\n",
    "\n",
    "一般而言，神经网络在神经元的基础上多了若干隐藏层（Hidden Layer）。所谓「隐藏」（hidden）的意思是：其输出对用户而言是不可见的——我们只能看到最后一组激励的输出结果。\n",
    "\n",
    "这些隐藏层的结点被称为「激励」（Activation） $a^{(i)}$，每个激励结点通过一组有向边（一组参数）与上一层所有激励结点（第一层激励 $a^{(1)} = x$）联系在一起；通过这种方法，神经网络可以拟合出更复杂的假设。\n",
    "\n",
    "### 前向传播算法（Forward Propagation）\n",
    "\n",
    "「前向」的意思是：从底层（即输入层）开始，逐层向上（向输出层）输出计算结果；每一层的输入是上一层激励结点。输入与输出的关系是\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "z^{(i)} = \\Theta^{(i)}a^{(i)}\\\\\n",
    "a^{(i + 1)} = g(z^{(i+1)})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "其中对矩阵 $\\Theta^{(i)}$ ：\n",
    "\n",
    "1. 其维度为 $S_(i+1) * (S_i + 1)$，$S_i$ 代表第 $i$ 层结点数（「+1」的意思是有 1 个偏置单元也产生了影响）\n",
    "2. 矩阵中的任一元素 $\\Theta^{(i)}_{m,n}$ 表示第 $i$ 层中第 $n$ 个单元对第 $i + 1$ 层中第 $m$ 个单元的影响（参数/权重）\n",
    "\n",
    "相应的反向传播算法（Back Propagation，BP）。。。？\n",
    "\n",
    "### 神经网络应用：逻辑运算\n",
    "\n",
    "考虑到对于 S 函数 $g(z)$ 是单调递增函数，且 $g(4.6) \\approx 0.99 \\approx 1$，$g(-4.6) \\approx 0.01 \\approx 1$，我们可以通过设计神经网络的参数来实现基本的逻辑运算；并通过把逻辑运算安排在不同层，实现不同逻辑运算的复杂组合。\n",
    "\n",
    "例如我们可以通过如下方法实现逻辑与（AND）、逻辑或（OR）、逻辑非（NOT）、逻辑异或（XOR）运算：神经网络有 3 层，隐藏层的两个结点分别为底层的逻辑与（AND）运算及逻辑表达式 $(\\lnot x_1) \\land (\\lnot x_2)$ 的运算结果；以隐藏层这 2 个激励结点为输入，进行逻辑或（OR）运算，最终得到的输出结果为逻辑异或运算（XOR）表达式 $x_1 XOR x_2$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "a^{(1)} &= x\\\\\n",
    "z^{(2)}_1 &= -30 + 20a^{(1)}_1 + 20a^{(1)}_2 &, & \\mbox{AND}\\\\\n",
    "z^{(2)}_2 &= 10 - 20a^{(1)}_1 - 20a^{(1)}_2 &, & (\\lnot x_1) \\land (\\lnot x_2)\\\\\n",
    "z^{(3)} &= -10 + 20a^{(2)}_1 + 20a^{(2)}_2 &, & \\mbox{OR}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 神经网络应用：多分类任务（Multiclass Classification）\n",
    "\n",
    "一个普通的逻辑回归/逻辑分类可用一个神经元/一个只有标量输出的神经网络来实现。需要执行多分类任务时，标量输出的神经网络将变成向量输出的神经网络，即输出层结点数由 1 变为 $n(n > 1)$.\n",
    "\n",
    "注意到对多分类神经网络而言，任一输入 $x$ 必满足下述条件之一：（设 $a^{(i)}$ 为最后一层激励结点亦即输出向量，为 $K$ 分类问题）\n",
    "\n",
    "1. $ \\sum^{j = 1}_k{a^{(i)_j}} = 1$（若输入 $x$ 在已有分类中，那么只有某个 $a^{(i)}_j = 1$，其余维度均为 0）\n",
    "2. $ \\sum^{j = 1}_k{a^{(i)_j}} = 0$（若输入 $x$ 不在已有分类中，那么 $\\forall j \\in [1, k],a^{(i)}_j = 0$）\n",
    "\n",
    "\n",
    "# 编程笔记\n",
    "\n",
    "## Week 02：线性回归（Linear Regression）\n",
    "\n",
    "根据手册（从[这里](https://s3.amazonaws.com/spark-public/ml/exercises/on-demand/machine-learning-ex1.zip)下载并解压得到的 `ex1.pdf`）的要求：\n",
    "\n",
    "（以下所谓的「键入命令」云云，均假设读者已打开 octave 并已经切换到练习文件夹下）\n",
    "\n",
    "### 1. 热身练习（Warm Up）\n",
    "\n",
    "手册 P2-3\n",
    "\n",
    "在 `warmUpExercise.m` 文件中输入代码，将 1 个 5\\*5 的单位矩阵赋给 A\n",
    "\n",
    "### 2. 尝试提交（Submit）\n",
    "\n",
    "手册 P2-3\n",
    "\n",
    "键入 `submit` 并根据提示分别输入 email 地址以及唯一身份标识符（即 Generate new token 上方那串字符）以提交作业。如果「热身练习」正确，应见到下述提示：\n",
    "\n",
    "```bash\n",
    "==                    Part Name |     Score | Feedback                                             \n",
    "==                    --------- |     ----- | --------                                             \n",
    "==             Warm-up Exercise |  10 /  10 | Nice work!\n",
    "```\n",
    "\n",
    "### 3. 绘制数据（Plot Data）\n",
    "\n",
    "手册 P4\n",
    "\n",
    "根据手册要求，在 `plotData.m` 中填写相应代码以绘制原始数据\n",
    "\n",
    "### 4. 代价函数（Cost Function）\n",
    "\n",
    "手册 P5-6\n",
    "\n",
    "根据代价函数的定义，在 `computeCost.m` 中写出 J 的表达式。注意几点：\n",
    "\n",
    "- theta/X/y 的维度分别是多少？\n",
    "- 对谁求平方？表达式是什么？是否需要加「.」？\n",
    "- 对谁求和？表达式是什么？是否需要加括弧？\n",
    "\n",
    "### 5. 批量梯度下降法（Batch Gradient Descent）\n",
    "\n",
    "手册 P6 最上方的公式\n",
    "\n",
    "关键是：能不能把代码缩为一句？\n",
    "\n",
    "我的尝试结果是：可以。(YOUR CODE HERE 处的)代码为\n",
    "\n",
    "```octave\n",
    "theta = theta - alpha * 1 / m * [sum((theta'*X' - y') .* X(:,1)'); sum((theta'*X' - y') .* X(:,2)')]; % version 01\n",
    "```\n",
    "\n",
    "version 01 不是最简单的代码，不过总算缩成了一句。以下贴出我的思考过程，如果有更简单的代码欢迎交流：\n",
    "\n",
    "1. 我们的修改对象是 theta，因此等式左侧是 1 个 n * 1 的矩阵（向量）；n 多大，取决于有多少参数 theta[j]，即有多少特征。在当前例子中，n = 2\n",
    "    - 为什么说当前例子中 n = 2？请查看 `ex1.m` 中 `theta = gradientDescent(X, y, theta, alpha, iterations);` 这句代码以上的部分\n",
    "\n",
    "2. 公式中的 alpha 和 1/m 都是数，因此关键是通过向量化 $ \\sum_{i=1}^m (h_{\\theta} (x^{(i)})- y^{(i)})x^{i}_j $ 把该公式的结果打包在 1 个 2 * 1 的矩阵（向量）中\n",
    "\n",
    "3. 以改变 theta[0] 为例：\n",
    "    1. 求和符号中的单位项应为：第 i 个样本点假设值和真实值的差，乘上第 i 个样本点的第 0 个特征的值 $ x^{i}_0 $\n",
    "    2. 有 97 个样本点，因此要求 97 次乘积，想到应该用向量「点」乘（即 Octave 中提供的「两个同维度矩阵中对应元素相乘」的操作，不是数学上的「点乘」，）\n",
    "    3. 求完这些乘积后，再求和，故乘积要在求和号之内\n",
    "    4. 再考虑一下 theta/X/y 的维度\n",
    "\n",
    "4. 改变 theta[1] 也是同样的道理，因此有了上述代码 version 01\n",
    "\n",
    "**问题**在于：\n",
    "\n",
    "> 一旦参数数量达到 10 以上，这样写就显得极其冗长了。    \n",
    "> 在这种情况下，应该如何精简代码？通过在内部加 1 个 for 循环遍历每个 theta[j]？有没有向量化的写法？\n",
    "\n",
    "有向量化的写法，这就是如下代码：\n",
    "\n",
    "```octave\n",
    "theta = theta - alpha * 1 / m * ((theta'*X' - y') * X)'; % version 02\n",
    "```\n",
    "\n",
    "为什么这么写？因为矩阵乘法本身的意义（想看看，如果 $A_{m,s} * B _{s, n} = C_{m,n}，那么 $$c_{i,j}$ 与 $A_{m,s}$ 及 $B _{s, n}$ 中元素的关系是什么？），我们不需要利用求和函数`sum()`。\n",
    "\n",
    "\n",
    "由于乘积中有一项就是对样本点 $x^{(i)}$ 的预测值与其真实值的差 $(h_{\\theta} (x^{(i)})- y^{(i)})$，另一项则是该点在第 j 个特征下的取值。把第 j 个特征下的每一个样本点的差值与特征值相乘，最后把这些乘积相加，得到的那个数，就是第 j 个特征贡献给第 j 个参数 $\\theta_j$ 的改变量。\n",
    "\n",
    "所有样本点的预测值与真实值之差写成矩阵就是 $(\\theta^{T}X^{T} - y^{T})$，它将参与每一个参数的改变，所以，把该项放在**左阵**的位置（1 \\* 97）；\n",
    "\n",
    "而**右阵**的每一列则代表一个**特征量向量 $x_j$**（某一列即代表某一个特征 $x_j$，这一列包含了所有样本点在特征下的取值 $x^{(1)}_j,\\cdots,x^{(i)}_j,\\cdots,x^{(m)_j}$），这个例子中有 2 个特征（n = 2），97 个样本（m = 97），因此 X 是 97 \\* 2 的矩阵。\n",
    "\n",
    "> 这里，可以画个简图，即用 1 \\* m 的行向量（「偏差矩阵」），去乘以 n \\* m 的矩阵（「特征量矩阵」），可能就比较好理解为什么把公共部分（「偏差矩阵」）放在左侧了。\n",
    "\n",
    "注意得到的矩阵是 1 \\* n （n 即特征数） 的，因此在进行矩阵乘法运算后，应该转置，才能参与矩阵减法及矩阵赋值的后续运算（左侧矩阵是 n \\* 1 的）。\n",
    "\n",
    "## Week 03：逻辑回归（Logistic Regression）\n",
    "\n",
    "### opt01. 绘制数据（可选练习）\n",
    "\n",
    "。。。`plotData.m`（待补充，ex2.pdf - P3）\n",
    "\n",
    "### submit01. 计算 S 型函数\n",
    "\n",
    "手册 P4\n",
    "\n",
    "这里涉及到 3 个知识点：\n",
    "\n",
    "1. `size(Matrix)` 将返回 1 个 1 \\* 2 的矩阵，表示矩阵 Matrix 的行数与列数\n",
    "2. `zeros(howBig)` 将返回一个维度为 howBig 的零矩阵。若 howBig 为数字 n，则返回 n \\* n 的零矩阵；若 howBig 为 `[rowNum colNum]` 形式的矩阵，则返回 rowNum \\* colNum 的零矩阵\n",
    "3. **（！最大的坑）**若运算符 operation 的操作对象是矩阵 Matrix 中的每一个元素，只要对 Matrix 施加 operation，同时在 operation 前加「.」即可\n",
    "\n",
    "这意味着，submit01 的答案应为：\n",
    "\n",
    "```octave\n",
    "g = 1 ./ (1 + e.^(-z))\n",
    "```\n",
    "### submit02. 代价函数与梯度\n",
    "\n",
    "手册 P4-5\n",
    "\n",
    "没什么新鲜的，参考 week02 的作业，注意运算对象之间的维度，必要时使用点运算符「.」；以及记得在必要时通过使用向量化的方法缩短代码。附代码如下：\n",
    "\n",
    "```octave\n",
    "J = -1 / m * (sum(y' .* log(1 ./ (1 + e .^ (-theta' * X')))) +\\\n",
    "              sum((ones(size(y)) - y)' .* log(1 - 1 ./ (1 + e .^ (-theta' * X')))))\n",
    "\n",
    "grad = 1 / m * ((1 ./ (1 + e .^ (-theta' * X')) - y') * X)'\n",
    "```\n",
    "\n",
    "### opt02. 使用 `fminunc` 学习参数（可选）\n",
    "\n",
    "。。。`plotDesicionBoundary.m`（待补充，ex2.pdf - P5-6）\n",
    "\n",
    "### submit03. 逻辑回归评估\n",
    "\n",
    "对每个给定的输入 x，我们需要根据模型计算其对应的标签；这一过程通过计算 $P(y = 1|x;\\theta) = h_\\theta(x) = g(\\theta^{T}x)$ 得到。\n",
    "\n",
    "其中，函数 $g$ 即 s 型函数，调用已经写好的 `sigmoid.m` 即可。\n",
    "\n",
    "至于 s 型函数计算出的结果，是 0~1 之间的小数；某个 x 对应哪个标签，取决于计算结果四舍五入后是 0 还是 1；由于其他编程语言中 `round()` 是四舍五入函数，因此尝试使用，发现确实可用。\n",
    "\n",
    "故代码如下：\n",
    "\n",
    "```octave\n",
    "p = round(sigmoid(theta' * X'))\n",
    "```\n",
    "\n",
    "### submit04. 逻辑回归正则化\n",
    "\n",
    "手册 P8-10\n",
    "\n",
    "这一次需要的决策边界显然不是直线。因此需要使用高次幂来拟合函数。特征项已经映射成了一组 28 维的向量，这过程不需要我们手动操作。\n",
    "\n",
    "使用了更高次幂，意味着我们需要使用正则化方法来避免过拟合问题。\n",
    "\n",
    "正则化方法的表达式书写并没有什么新意。只有 1 点要提醒注意：\n",
    "\n",
    "> 参与正则化的参数下标从 1 开始\n",
    "\n",
    "那么我们只要事先构造一组向量\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0\\\\\\theta_1\\\\\\theta_2\\\\\\vdots\\\\\\theta_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "然后就能在原来而代价函数与梯度上简单修改得到结果。关键代码如下\n",
    "\n",
    "```octave\n",
    "reg_item = [0; theta(2:size(theta))]\n",
    "\n",
    "J = 1 / m * (-sum(y' .* log(1 ./ (1 + e .^ (-theta' * X')))) -\\\n",
    "              sum((ones(size(y)) - y)' .* log(1 - 1 ./ (1 + e .^ (-theta' * X'))))) \\\n",
    "  + lambda / (2 * m) * sum(reg_item .^ 2)\n",
    "\n",
    "grad = 1 / m * ((1 ./ (1 + e .^ (-theta' * X')) - y') * X)' + lambda / m * reg_item\n",
    "```\n",
    "\n",
    "## Week 04：神经网络（Neural Network）\n",
    "\n",
    "### submit01. 逻辑回归向量化（Vectorizing Logistic Regression）\n",
    "\n",
    "由于之前的代码我就考虑了向量化，因此此处直接应用 Week03 中正则化后的代价函数与梯度的代码即可：\n",
    "\n",
    "```octave\n",
    "reg_item = [0; theta(2:size(theta))]\n",
    "\n",
    "J = 1 / m * (-sum(y' .* log(1 ./ (1 + e .^ (-theta' * X')))) -\\\n",
    "sum((ones(size(y)) - y)' .* log(1 - 1 ./ (1 + e .^ (-theta' * X'))))) \\\n",
    "+ lambda / (2 * m) * sum(reg_item .^ 2)\n",
    "\n",
    "grad = 1 / m * ((1 ./ (1 + e .^ (-theta' * X')) - y') * X)' + lambda / m * reg_item\n",
    "```\n",
    "### submit02. 一对多分类（One-vs-all Classification）\n",
    "\n",
    "这里要训练出一个可识别数字 1~10 的分类器。如何训练 10 个分类器？只要能够每次训练 1 个分类器，循环 10 次即可。\n",
    "\n",
    "那么如何训练出 1 个分类器？也就是说给定 1 个输入，分类器将认为该输入属于类别 c 或不属于类别 c。所以这实际上是逻辑回归的问题。\n",
    "\n",
    "那么如果放在逻辑回归的语境下，我们是怎么训练出分类器的呢？实际上我们是通过将一个又一个训练样本输入程序，程序计算出当前分类器（实际上是一个带参数 $\\theta$ 的假设函数 $h_\\theta(x)$）计算结果与真实结果之间的差距从而计算出代价 $J(\\theta)$；然后程序根据代价变化调整 $\\theta$，直到 $J(\\theta)$ 收敛到全局最小值，此时分类器训练完毕。\n",
    "\n",
    "> 也就是说我们的目标是：**找到使代价 $J(\\theta)$ 最小的 $\\theta$**\n",
    "\n",
    "关键是改变 $\\theta$，那么如何实现 $\\theta$ 的改变？\n",
    "\n",
    "1. 梯度下降法（Gradient Descent）——在线性回归和逻辑回归问题中，我们都是这么做的。\n",
    "2. 当数据规模变大时，可以考虑不使用梯度下降法，而使用已有的库来实现更高级的算法（例如系统的 `fminunc` 或者本次作业手册中提到的 `fmincg`）。\n",
    "\n",
    "\n",
    "### submit03. 一对多预测（One-vs-all Prediction）\n",
    "\n",
    "。。。\n",
    "\n",
    "### submit04. 前向传播与预测（Forward Propagation and Prediction）\n",
    "\n",
    "。。。\n",
    "\n",
    "# 参考资料\n",
    "\n",
    "1. [Machine learning on Coursera](https://www.coursera.org/learn/machine-learning), by [Andrew Ng](http://www.andrewng.org/)\n",
    "2. [维基百科·帮助:数学公式](https://zh.wikipedia.org/wiki/Help:%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
